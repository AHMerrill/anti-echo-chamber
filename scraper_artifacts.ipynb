{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Setup 1 of N: environment and workspace\n",
        "\n",
        "Goal\n",
        "- Install core dependencies for scraping, embeddings, and Chroma\n",
        "- Create a clean workspace in `/content/anti_echo`\n",
        "- Print basic environment info so collaborators can debug quickly\n",
        "\n",
        "Notes\n",
        "- No Drive mount\n",
        "- Keep installs minimal and pinned where sensible\n"
      ],
      "metadata": {
        "id": "z3lyMabwG0TZ"
      },
      "id": "z3lyMabwG0TZ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup 1 of N: environment and workspace\n",
        "# Colab safe. No Drive mount.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import textwrap\n",
        "from pathlib import Path\n",
        "\n",
        "def pip_install(pkgs):\n",
        "    cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"-q\"] + pkgs\n",
        "    print(\"Installing:\", \" \".join(pkgs))\n",
        "    subprocess.check_call(cmd)\n",
        "\n",
        "# Core deps\n",
        "pip_install([\n",
        "    \"feedparser==6.0.10\",\n",
        "    \"trafilatura>=1.6.2,<2.0\",\n",
        "    \"sentence-transformers>=2.6.1,<3.0\",\n",
        "    \"chromadb>=0.5.5,<0.6.0\",\n",
        "    \"huggingface_hub>=0.24.0,<0.28.0\",\n",
        "    \"pyyaml>=6.0.1,<7.0\",\n",
        "    \"numpy>=1.26.4,<3.0\",\n",
        "    \"tqdm>=4.66.0,<5.0\",\n",
        "    \"requests>=2.31.0,<3.0\",\n",
        "    \"rapidfuzz>=3.6.0,<4.0\"\n",
        "])\n",
        "\n",
        "# Optional but helpful\n",
        "try:\n",
        "    import torch\n",
        "except Exception:\n",
        "    pip_install([\"torch>=2.2.0,<3.0\"])\n",
        "\n",
        "# Workspace layout\n",
        "PROJECT_ROOT = Path(\"/content/anti_echo\").resolve()\n",
        "SUBDIRS = [\n",
        "    \"raw\",\n",
        "    \"batches\",\n",
        "    \"chroma_db\",\n",
        "    \"logs\",\n",
        "    \"feeds\",\n",
        "    \"tmp\"\n",
        "]\n",
        "\n",
        "for d in SUBDIRS:\n",
        "    (PROJECT_ROOT / d).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Environment tweaks\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "# Diagnostics\n",
        "import platform, json\n",
        "from importlib.metadata import version, PackageNotFoundError\n",
        "\n",
        "def v(name):\n",
        "    try:\n",
        "        return version(name)\n",
        "    except PackageNotFoundError:\n",
        "        return \"not-installed\"\n",
        "\n",
        "info = {\n",
        "    \"python\": sys.version.split()[0],\n",
        "    \"platform\": platform.platform(),\n",
        "    \"cuda_available\": False,\n",
        "    \"packages\": {\n",
        "        \"feedparser\": v(\"feedparser\"),\n",
        "        \"trafilatura\": v(\"trafilatura\"),\n",
        "        \"sentence-transformers\": v(\"sentence-transformers\"),\n",
        "        \"chromadb\": v(\"chromadb\"),\n",
        "        \"huggingface_hub\": v(\"huggingface-hub\"),\n",
        "        \"pyyaml\": v(\"PyYAML\"),\n",
        "        \"numpy\": v(\"numpy\"),\n",
        "        \"rapidfuzz\": v(\"rapidfuzz\"),\n",
        "        \"torch\": v(\"torch\"),\n",
        "        \"tqdm\": v(\"tqdm\"),\n",
        "        \"requests\": v(\"requests\"),\n",
        "    },\n",
        "    \"paths\": {\n",
        "        \"project_root\": str(PROJECT_ROOT),\n",
        "        \"raw\": str(PROJECT_ROOT / \"raw\"),\n",
        "        \"batches\": str(PROJECT_ROOT / \"batches\"),\n",
        "        \"chroma_db\": str(PROJECT_ROOT / \"chroma_db\"),\n",
        "        \"logs\": str(PROJECT_ROOT / \"logs\"),\n",
        "        \"feeds\": str(PROJECT_ROOT / \"feeds\"),\n",
        "        \"tmp\": str(PROJECT_ROOT / \"tmp\"),\n",
        "    }\n",
        "}\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    info[\"cuda_available\"] = bool(torch.cuda.is_available())\n",
        "    if info[\"cuda_available\"]:\n",
        "        info[\"cuda_device_name\"] = torch.cuda.get_device_name(0)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "print(json.dumps(info, indent=2))\n",
        "\n",
        "# Place a small README in the workspace for orientation\n",
        "workspace_readme = PROJECT_ROOT / \"README_WORKSPACE.txt\"\n",
        "if not workspace_readme.exists():\n",
        "    workspace_readme.write_text(textwrap.dedent(\"\"\"\n",
        "        anti echo chamber - Colab workspace\n",
        "        This directory is ephemeral per session.\n",
        "        Do not commit files from here directly.\n",
        "        Subdirs:\n",
        "          raw        - local scraped texts and meta for this session\n",
        "          batches    - locally packaged batches before HF upload\n",
        "          chroma_db  - local Chroma rebuild target\n",
        "          logs       - run logs\n",
        "          feeds      - runtime feed artifacts\n",
        "          tmp        - scratch space\n",
        "    \"\"\").strip() + \"\\n\", encoding=\"utf-8\")\n",
        "print(f\"Workspace ready at {PROJECT_ROOT}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zffpD2rNG0Ax",
        "outputId": "8033e243-40d0-43ed-cc3c-94415a751f3d"
      },
      "id": "zffpD2rNG0Ax",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing: feedparser==6.0.10 trafilatura>=1.6.2,<2.0 sentence-transformers>=2.6.1,<3.0 chromadb>=0.5.5,<0.6.0 huggingface_hub>=0.24.0,<0.28.0 pyyaml>=6.0.1,<7.0 numpy>=1.26.4,<3.0 tqdm>=4.66.0,<5.0 requests>=2.31.0,<3.0 rapidfuzz>=3.6.0,<4.0\n",
            "{\n",
            "  \"python\": \"3.12.11\",\n",
            "  \"platform\": \"Linux-6.6.97+-x86_64-with-glibc2.35\",\n",
            "  \"cuda_available\": true,\n",
            "  \"packages\": {\n",
            "    \"feedparser\": \"6.0.10\",\n",
            "    \"trafilatura\": \"1.8.1\",\n",
            "    \"sentence-transformers\": \"2.7.0\",\n",
            "    \"chromadb\": \"0.5.23\",\n",
            "    \"huggingface_hub\": \"0.27.1\",\n",
            "    \"pyyaml\": \"6.0.3\",\n",
            "    \"numpy\": \"1.26.4\",\n",
            "    \"rapidfuzz\": \"3.14.1\",\n",
            "    \"torch\": \"2.8.0+cu126\",\n",
            "    \"tqdm\": \"4.67.1\",\n",
            "    \"requests\": \"2.32.4\"\n",
            "  },\n",
            "  \"paths\": {\n",
            "    \"project_root\": \"/content/anti_echo\",\n",
            "    \"raw\": \"/content/anti_echo/raw\",\n",
            "    \"batches\": \"/content/anti_echo/batches\",\n",
            "    \"chroma_db\": \"/content/anti_echo/chroma_db\",\n",
            "    \"logs\": \"/content/anti_echo/logs\",\n",
            "    \"feeds\": \"/content/anti_echo/feeds\",\n",
            "    \"tmp\": \"/content/anti_echo/tmp\"\n",
            "  },\n",
            "  \"cuda_device_name\": \"NVIDIA A100-SXM4-40GB\"\n",
            "}\n",
            "Workspace ready at /content/anti_echo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup 2 of N: config and paths bootstrap (robust fetch)\n",
        "\n",
        "Goal\n",
        "- Load shared config from GitHub with fallback paths\n",
        "- Cache config locally for this session\n",
        "- Initialize runtime paths and print key settings\n",
        "\n",
        "Note\n",
        "- Tries multiple candidate filenames for `stance_axes` and `topic_labels` in case they are saved with .json or .yaml\n"
      ],
      "metadata": {
        "id": "rJEp6xNjHjAz"
      },
      "id": "rJEp6xNjHjAz"
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup 2 of N: config and paths bootstrap (robust fetch)\n",
        "\n",
        "import os\n",
        "import json\n",
        "import yaml\n",
        "import requests\n",
        "from pathlib import Path\n",
        "\n",
        "PROJECT_ROOT = Path(\"/content/anti_echo\").resolve()\n",
        "CONFIG_CACHE = PROJECT_ROOT / \"config_cache\"\n",
        "CONFIG_CACHE.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "REPO_OWNER = \"AHMerrill\"\n",
        "REPO_NAME = \"anti-echo-chamber\"\n",
        "BRANCH = \"main\"\n",
        "\n",
        "def raw_url(path: str) -> str:\n",
        "    return f\"https://raw.githubusercontent.com/{REPO_OWNER}/{REPO_NAME}/{BRANCH}/{path.lstrip('/')}\"\n",
        "\n",
        "def fetch_text_first(paths):\n",
        "    last_err = None\n",
        "    tried = []\n",
        "    for p in paths:\n",
        "        url = raw_url(p)\n",
        "        tried.append(url)\n",
        "        try:\n",
        "            r = requests.get(url, timeout=20)\n",
        "            if r.status_code == 200 and r.text.strip():\n",
        "                return r.text, p, url\n",
        "        except Exception as e:\n",
        "            last_err = e\n",
        "    msg = \"Could not fetch any of the candidate paths.\\nTried:\\n\" + \"\\n\".join(tried)\n",
        "    if last_err:\n",
        "        msg += f\"\\nLast error: {type(last_err).__name__}: {last_err}\"\n",
        "    raise RuntimeError(msg)\n",
        "\n",
        "# Candidate repo paths\n",
        "CFG_CANDIDATES = [\n",
        "    \"config/config.yaml\",\n",
        "    \"config/config.yml\",\n",
        "    \"config/config.json\",\n",
        "]\n",
        "STANCE_CANDIDATES = [\n",
        "    \"config/stance_axes.json\",\n",
        "    \"config/stance_axes.yaml\",\n",
        "    \"config/stance_axes.yml\",\n",
        "    \"config/stance_axes\",\n",
        "]\n",
        "TOPIC_CANDIDATES = [\n",
        "    \"config/topic_labels.json\",\n",
        "    \"config/topic_labels.yaml\",\n",
        "    \"config/topic_labels.yml\",\n",
        "    \"config/topic_labels\",\n",
        "]\n",
        "\n",
        "# Fetch config files\n",
        "cfg_txt, cfg_path, cfg_url = fetch_text_first(CFG_CANDIDATES)\n",
        "stance_txt, stance_path, stance_url = fetch_text_first(STANCE_CANDIDATES)\n",
        "topic_txt, topic_path, topic_url = fetch_text_first(TOPIC_CANDIDATES)\n",
        "\n",
        "# Cache copies\n",
        "(CONFIG_CACHE / Path(cfg_path).name).write_text(cfg_txt, encoding=\"utf-8\")\n",
        "(CONFIG_CACHE / (Path(stance_path).name if Path(stance_path).suffix else \"stance_axes.json\")).write_text(stance_txt, encoding=\"utf-8\")\n",
        "(CONFIG_CACHE / (Path(topic_path).name if Path(topic_path).suffix else \"topic_labels.json\")).write_text(topic_txt, encoding=\"utf-8\")\n",
        "\n",
        "# Parse helpers\n",
        "def parse_maybe_json_or_yaml(txt: str):\n",
        "    txt = txt.strip()\n",
        "    # try json first\n",
        "    try:\n",
        "        return json.loads(txt)\n",
        "    except Exception:\n",
        "        pass\n",
        "    # then yaml\n",
        "    try:\n",
        "        return yaml.safe_load(txt)\n",
        "    except Exception as e:\n",
        "        raise ValueError(f\"Failed to parse as JSON or YAML: {e}\")\n",
        "\n",
        "# Parse into Python objects\n",
        "if cfg_path.endswith((\".yaml\", \".yml\")):\n",
        "    CONFIG = yaml.safe_load(cfg_txt)\n",
        "elif cfg_path.endswith(\".json\"):\n",
        "    CONFIG = json.loads(cfg_txt)\n",
        "else:\n",
        "    # default to YAML for config\n",
        "    CONFIG = yaml.safe_load(cfg_txt)\n",
        "\n",
        "STANCE_AXES = parse_maybe_json_or_yaml(stance_txt)\n",
        "TOPIC_LABELS = parse_maybe_json_or_yaml(topic_txt)\n",
        "\n",
        "# Validate minimum keys\n",
        "required_cfg_keys = [\"hf_dataset_id\", \"chroma_collections\", \"embeddings\", \"batch\", \"ids\", \"chroma\"]\n",
        "missing = [k for k in required_cfg_keys if k not in CONFIG]\n",
        "if missing:\n",
        "    raise ValueError(f\"Missing required config keys: {missing}\")\n",
        "\n",
        "# Create runtime subdirs\n",
        "for key, path in {\n",
        "    \"raw\": \"raw\",\n",
        "    \"batches\": CONFIG[\"batch\"][\"base_dir\"],\n",
        "    \"chroma_db\": CONFIG[\"chroma\"][\"dir\"],\n",
        "    \"logs\": CONFIG.get(\"logging\", {}).get(\"save_dir\", \"logs\"),\n",
        "    \"tmp\": \"tmp\"\n",
        "}.items():\n",
        "    (PROJECT_ROOT / path).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Print a concise summary\n",
        "summary = {\n",
        "    \"hf_dataset_id\": CONFIG[\"hf_dataset_id\"],\n",
        "    \"collections\": CONFIG[\"chroma_collections\"],\n",
        "    \"embeddings\": {\n",
        "        \"topic_model\": CONFIG[\"embeddings\"][\"topic_model\"],\n",
        "        \"stance_model\": CONFIG[\"embeddings\"][\"stance_model\"],\n",
        "        \"dim\": CONFIG[\"embeddings\"][\"dim\"],\n",
        "        \"dtype\": CONFIG[\"embeddings\"][\"dtype\"],\n",
        "        \"pooling\": CONFIG[\"embeddings\"][\"pooling\"],\n",
        "        \"chunk_tokens\": CONFIG[\"embeddings\"][\"chunk_tokens\"]\n",
        "    },\n",
        "    \"summarizer\": CONFIG.get(\"summarizer\", {}),\n",
        "    \"batch_files\": {\n",
        "        \"topic_file\": CONFIG[\"batch\"][\"topic_file\"],\n",
        "        \"stance_file\": CONFIG[\"batch\"][\"stance_file\"],\n",
        "        \"metadata_file\": CONFIG[\"batch\"][\"metadata_file\"],\n",
        "        \"manifest_name\": CONFIG[\"batch\"][\"manifest_name\"],\n",
        "        \"base_dir\": CONFIG[\"batch\"][\"base_dir\"]\n",
        "    },\n",
        "    \"id_policy\": CONFIG[\"ids\"],\n",
        "    \"paths\": {\n",
        "        \"project_root\": str(PROJECT_ROOT),\n",
        "        \"config_cache\": str(CONFIG_CACHE),\n",
        "        \"raw\": str(PROJECT_ROOT / \"raw\"),\n",
        "        \"batches\": str(PROJECT_ROOT / CONFIG[\"batch\"][\"base_dir\"]),\n",
        "        \"chroma_db\": str(PROJECT_ROOT / CONFIG[\"chroma\"][\"dir\"]),\n",
        "        \"logs\": str(PROJECT_ROOT / CONFIG.get(\"logging\", {}).get(\"save_dir\", \"logs\")),\n",
        "        \"tmp\": str(PROJECT_ROOT / \"tmp\")\n",
        "    },\n",
        "    \"loaded\": {\n",
        "        \"stance_axes_count\": len(STANCE_AXES) if isinstance(STANCE_AXES, (list, dict)) else \"unknown\",\n",
        "        \"topic_labels_count\": len(TOPIC_LABELS) if isinstance(TOPIC_LABELS, (list, dict)) else \"unknown\"\n",
        "    },\n",
        "    \"source_urls\": {\n",
        "        \"config\": cfg_url,\n",
        "        \"stance_axes\": stance_url,\n",
        "        \"topic_labels\": topic_url\n",
        "    }\n",
        "}\n",
        "\n",
        "print(json.dumps(summary, indent=2))\n",
        "\n",
        "# Make HF dataset id available to later cells\n",
        "os.environ[\"HF_DATASET_ID\"] = CONFIG[\"hf_dataset_id\"]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhAwiP7LHjgu",
        "outputId": "256b3998-9f52-4e79-d29c-0d34451b2540"
      },
      "id": "vhAwiP7LHjgu",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"hf_dataset_id\": \"zanimal/anti-echo-artifacts\",\n",
            "  \"collections\": {\n",
            "    \"topic\": \"news_topic\",\n",
            "    \"stance\": \"news_stance\"\n",
            "  },\n",
            "  \"embeddings\": {\n",
            "    \"topic_model\": \"sentence-transformers/all-MiniLM-L6-v2\",\n",
            "    \"stance_model\": \"sentence-transformers/all-MiniLM-L6-v2\",\n",
            "    \"dim\": 384,\n",
            "    \"dtype\": \"float16\",\n",
            "    \"pooling\": \"mean\",\n",
            "    \"chunk_tokens\": 512\n",
            "  },\n",
            "  \"summarizer\": {\n",
            "    \"model\": \"facebook/bart-large-cnn\",\n",
            "    \"target_sentences\": 5,\n",
            "    \"truncation\": 2048\n",
            "  },\n",
            "  \"batch_files\": {\n",
            "    \"topic_file\": \"embeddings_topic.npz\",\n",
            "    \"stance_file\": \"embeddings_stance.npz\",\n",
            "    \"metadata_file\": \"metadata.jsonl\",\n",
            "    \"manifest_name\": \"manifest.json\",\n",
            "    \"base_dir\": \"batches\"\n",
            "  },\n",
            "  \"id_policy\": {\n",
            "    \"scheme\": \"domain-slug-sha12\",\n",
            "    \"hash\": \"sha256\",\n",
            "    \"normalize_whitespace\": true,\n",
            "    \"lowercase\": true\n",
            "  },\n",
            "  \"paths\": {\n",
            "    \"project_root\": \"/content/anti_echo\",\n",
            "    \"config_cache\": \"/content/anti_echo/config_cache\",\n",
            "    \"raw\": \"/content/anti_echo/raw\",\n",
            "    \"batches\": \"/content/anti_echo/batches\",\n",
            "    \"chroma_db\": \"/content/anti_echo/chroma_db\",\n",
            "    \"logs\": \"/content/anti_echo/logs\",\n",
            "    \"tmp\": \"/content/anti_echo/tmp\"\n",
            "  },\n",
            "  \"loaded\": {\n",
            "    \"stance_axes_count\": 49,\n",
            "    \"topic_labels_count\": 24\n",
            "  },\n",
            "  \"source_urls\": {\n",
            "    \"config\": \"https://raw.githubusercontent.com/AHMerrill/anti-echo-chamber/main/config/config.yaml\",\n",
            "    \"stance_axes\": \"https://raw.githubusercontent.com/AHMerrill/anti-echo-chamber/main/config/stance_axes.json\",\n",
            "    \"topic_labels\": \"https://raw.githubusercontent.com/AHMerrill/anti-echo-chamber/main/config/topic_labels.json\"\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup 3 of N: Hugging Face auth and registry pull\n",
        "\n",
        "Goal\n",
        "- Authenticate to Hugging Face with HF_TOKEN\n",
        "- Fetch the batch registry from GitHub\n",
        "- Validate the registry schema and summarize batches\n",
        "\n",
        "Notes\n",
        "- If HF_TOKEN is not set, you can still proceed to read public data but uploads will fail later\n",
        "- The registry lives at artifacts/artifacts_registry.json in your GitHub repo\n"
      ],
      "metadata": {
        "id": "7FuW4A7ELmrx"
      },
      "id": "7FuW4A7ELmrx"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- temporary auth cell for Colab session ---\n",
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "if \"HF_TOKEN\" not in os.environ or not os.environ[\"HF_TOKEN\"].strip():\n",
        "    os.environ[\"HF_TOKEN\"] = getpass(\"Enter your Hugging Face token: \")\n",
        "\n",
        "print(\"HF_TOKEN set in environment for this session (will reset when runtime restarts).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZlphFLgMJWk",
        "outputId": "63a71082-25e1-4a89-bb0c-19358a0bd6b6"
      },
      "id": "8ZlphFLgMJWk",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your Hugging Face token: ··········\n",
            "HF_TOKEN set in environment for this session (will reset when runtime restarts).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup 3 of N: Hugging Face auth and registry pull\n",
        "\n",
        "import os\n",
        "import json\n",
        "import requests\n",
        "from pathlib import Path\n",
        "from huggingface_hub import login, HfApi\n",
        "\n",
        "PROJECT_ROOT = Path(\"/content/anti_echo\").resolve()\n",
        "CACHE_DIR = PROJECT_ROOT / \"registry_cache\"\n",
        "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "REPO_OWNER = \"AHMerrill\"\n",
        "REPO_NAME = \"anti-echo-chamber\"\n",
        "BRANCH = \"main\"\n",
        "\n",
        "def raw_url(path: str) -> str:\n",
        "    return f\"https://raw.githubusercontent.com/{REPO_OWNER}/{REPO_NAME}/{BRANCH}/{path.lstrip('/')}\"\n",
        "\n",
        "# 1) HF auth\n",
        "HF_TOKEN = os.environ.get(\"HF_TOKEN\", \"\").strip()\n",
        "if HF_TOKEN:\n",
        "    try:\n",
        "        login(token=HF_TOKEN, add_to_git_credential=False)\n",
        "        print(\"Hugging Face login: OK\")\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: HF login failed: {type(e).__name__}: {e}\")\n",
        "else:\n",
        "    print(\"Warning: HF_TOKEN not set. You can read public artifacts but cannot upload.\")\n",
        "\n",
        "# 2) Validate the dataset exists\n",
        "HF_DATASET_ID = os.environ.get(\"HF_DATASET_ID\", \"\").strip()\n",
        "if not HF_DATASET_ID:\n",
        "    raise RuntimeError(\"HF_DATASET_ID not set in environment. It should have been set by Setup 2 from config.\")\n",
        "try:\n",
        "    api = HfApi()\n",
        "    ds_info = api.repo_info(HF_DATASET_ID, repo_type=\"dataset\")\n",
        "    print(f\"HF dataset found: {HF_DATASET_ID}\")\n",
        "except Exception as e:\n",
        "    print(f\"Warning: Could not verify HF dataset {HF_DATASET_ID}: {type(e).__name__}: {e}\")\n",
        "\n",
        "# 3) Pull registry from GitHub\n",
        "REGISTRY_URL = raw_url(\"artifacts/artifacts_registry.json\")\n",
        "r = requests.get(REGISTRY_URL, timeout=20)\n",
        "if r.status_code != 200:\n",
        "    raise RuntimeError(f\"Failed to fetch registry from {REGISTRY_URL}. Status {r.status_code}\")\n",
        "registry_txt = r.text\n",
        "(REGISTRY_CACHE_PATH := CACHE_DIR / \"artifacts_registry.json\").write_text(registry_txt, encoding=\"utf-8\")\n",
        "\n",
        "try:\n",
        "    REGISTRY = json.loads(registry_txt)\n",
        "except Exception as e:\n",
        "    raise ValueError(f\"Registry JSON parse failed: {e}\")\n",
        "\n",
        "# 4) Minimal schema checks and summary\n",
        "required_top = [\"version\", \"models\", \"batches\"]\n",
        "missing = [k for k in required_top if k not in REGISTRY]\n",
        "if missing:\n",
        "    raise ValueError(f\"Registry missing required keys: {missing}\")\n",
        "\n",
        "models_block = REGISTRY.get(\"models\", {})\n",
        "batches = REGISTRY.get(\"batches\", [])\n",
        "model_summary = {\n",
        "    \"topic\": models_block.get(\"topic\"),\n",
        "    \"stance\": models_block.get(\"stance\"),\n",
        "    \"dim\": models_block.get(\"dim\")\n",
        "}\n",
        "\n",
        "summary = {\n",
        "    \"registry_version\": REGISTRY.get(\"version\"),\n",
        "    \"models\": model_summary,\n",
        "    \"batch_count\": len(batches),\n",
        "}\n",
        "\n",
        "# Print concise summary\n",
        "print(json.dumps(summary, indent=2))\n",
        "\n",
        "# If batches exist, show a compact table\n",
        "if batches:\n",
        "    rows = []\n",
        "    for b in batches:\n",
        "        rows.append({\n",
        "            \"batch_id\": b.get(\"batch_id\"),\n",
        "            \"docs\": b.get(\"counts\", {}).get(\"docs\"),\n",
        "            \"created_at\": b.get(\"created_at\"),\n",
        "        })\n",
        "    # Keep it readable\n",
        "    print(\"Batches overview:\")\n",
        "    for row in rows:\n",
        "        print(f\"- {row['batch_id']} | docs={row['docs']} | created_at={row['created_at']}\")\n",
        "else:\n",
        "    print(\"No batches listed yet in artifacts_registry.json\")\n",
        "\n",
        "# Make available to later cells\n",
        "os.environ[\"REGISTRY_PATH\"] = str(REGISTRY_CACHE_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8hxn43ELo1G",
        "outputId": "adcb560b-78bf-4728-f087-cf75cdfdf9ec"
      },
      "id": "w8hxn43ELo1G",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
            "WARNING:huggingface_hub._login:Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hugging Face login: OK\n",
            "HF dataset found: zanimal/anti-echo-artifacts\n",
            "{\n",
            "  \"registry_version\": 1,\n",
            "  \"models\": {\n",
            "    \"topic\": \"sentence-transformers/all-MiniLM-L6-v2\",\n",
            "    \"stance\": \"sentence-transformers/all-MiniLM-L6-v2\",\n",
            "    \"dim\": 384\n",
            "  },\n",
            "  \"batch_count\": 0\n",
            "}\n",
            "No batches listed yet in artifacts_registry.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup 4 of N: Chroma rebuild or initialize\n",
        "\n",
        "Goal\n",
        "- Create a persistent Chroma client under `/content/anti_echo/chroma_db`\n",
        "- Ensure two collections exist: `news_topic` and `news_stance`\n",
        "- If batches are listed in the registry, download and ingest them in order\n",
        "- If no batches yet, initialize empty collections and print a clear summary\n",
        "\n",
        "Notes\n",
        "- Uses `artifacts/artifacts_registry.json` as the source of truth\n",
        "- Validates shapes and dims before inserting\n",
        "- Safe to re run\n"
      ],
      "metadata": {
        "id": "B8nvAQxhNAcH"
      },
      "id": "B8nvAQxhNAcH"
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup 4 of N: Chroma rebuild or initialize\n",
        "\n",
        "import os\n",
        "import io\n",
        "import json\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Tuple\n",
        "from huggingface_hub import hf_hub_download\n",
        "import chromadb\n",
        "\n",
        "# Inputs from prior cells\n",
        "PROJECT_ROOT = Path(\"/content/anti_echo\").resolve()\n",
        "CHROMA_DIR = PROJECT_ROOT / \"chroma_db\"\n",
        "REGISTRY_PATH = Path(os.environ.get(\"REGISTRY_PATH\", PROJECT_ROOT / \"registry_cache\" / \"artifacts_registry.json\"))\n",
        "HF_DATASET_ID = os.environ[\"HF_DATASET_ID\"]\n",
        "\n",
        "# CONFIG must already be loaded in memory by Setup 2\n",
        "try:\n",
        "    CONFIG\n",
        "except NameError:\n",
        "    raise RuntimeError(\"CONFIG is not defined. Please run Setup 2 first.\")\n",
        "\n",
        "COLL_TOPIC = CONFIG[\"chroma_collections\"][\"topic\"]\n",
        "COLL_STANCE = CONFIG[\"chroma_collections\"][\"stance\"]\n",
        "EMB_DIM = int(CONFIG[\"embeddings\"][\"dim\"])\n",
        "\n",
        "def load_registry(path: Path) -> Dict:\n",
        "    if not path.exists():\n",
        "        raise FileNotFoundError(f\"Registry not found at {path}\")\n",
        "    return json.loads(path.read_text(encoding=\"utf-8\"))\n",
        "\n",
        "def read_metadata_jsonl(fp: Path) -> Tuple[List[str], List[Dict]]:\n",
        "    ids = []\n",
        "    metas = []\n",
        "    with fp.open(\"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            if not line.strip():\n",
        "                continue\n",
        "            obj = json.loads(line)\n",
        "            ids.append(obj[\"id\"])\n",
        "            metas.append(obj)\n",
        "    return ids, metas\n",
        "\n",
        "def load_npz_vectors(fp: Path, expected_dim: int) -> np.ndarray:\n",
        "    arr = np.load(fp)[\"arr_0\"] if \"arr_0\" in np.load(fp).files else np.load(fp, allow_pickle=False)\n",
        "    # If saved as a direct array with no key, np.load returns an ndarray, not an NpzFile\n",
        "    if isinstance(arr, np.lib.npyio.NpzFile):\n",
        "        # handle the case where npz contains a named array\n",
        "        keys = list(arr.files)\n",
        "        if not keys:\n",
        "            raise ValueError(f\"No arrays found in {fp.name}\")\n",
        "        arr = arr[keys[0]]\n",
        "    vecs = np.array(arr)\n",
        "    if vecs.ndim != 2 or vecs.shape[1] != expected_dim:\n",
        "        raise ValueError(f\"Bad embedding shape in {fp.name}. Got {vecs.shape}, expected [N, {expected_dim}]\")\n",
        "    if not np.isfinite(vecs).all():\n",
        "        raise ValueError(f\"Non finite values found in {fp.name}\")\n",
        "    return vecs\n",
        "\n",
        "def ensure_chroma():\n",
        "    client = chromadb.PersistentClient(path=str(CHROMA_DIR))\n",
        "    topic = client.get_or_create_collection(name=COLL_TOPIC, metadata={\"hnsw:space\": \"cosine\"})\n",
        "    stance = client.get_or_create_collection(name=COLL_STANCE, metadata={\"hnsw:space\": \"cosine\"})\n",
        "    return client, topic, stance\n",
        "\n",
        "def upsert_in_chunks(collection, ids: List[str], vectors: np.ndarray, metadatas: List[Dict], chunk: int = 2048):\n",
        "    n = len(ids)\n",
        "    for i in range(0, n, chunk):\n",
        "        j = min(i + chunk, n)\n",
        "        collection.upsert(\n",
        "            ids=ids[i:j],\n",
        "            embeddings=vectors[i:j].tolist(),\n",
        "            metadatas=metadatas[i:j],\n",
        "        )\n",
        "\n",
        "def ingest_batch_record(batch: Dict, topic_coll, stance_coll) -> Dict:\n",
        "    # Expect registry to store relative HF paths or full URLs. Prefer relative paths under batches/<batch_id>/*\n",
        "    topic_path = batch.get(\"hf_paths\", {}).get(\"embeddings_topic\")\n",
        "    stance_path = batch.get(\"hf_paths\", {}).get(\"embeddings_stance\")\n",
        "    meta_path = batch.get(\"hf_paths\", {}).get(\"metadata\")\n",
        "    manifest_path = batch.get(\"hf_paths\", {}).get(\"manifest\")\n",
        "    if not all([topic_path, stance_path, meta_path, manifest_path]):\n",
        "        raise ValueError(f\"Incomplete hf_paths in registry for batch {batch.get('batch_id')}\")\n",
        "\n",
        "    # Download artifacts from HF dataset\n",
        "    t_local = Path(hf_hub_download(repo_id=HF_DATASET_ID, repo_type=\"dataset\", filename=topic_path))\n",
        "    s_local = Path(hf_hub_download(repo_id=HF_DATASET_ID, repo_type=\"dataset\", filename=stance_path))\n",
        "    m_local = Path(hf_hub_download(repo_id=HF_DATASET_ID, repo_type=\"dataset\", filename=meta_path))\n",
        "    _ = Path(hf_hub_download(repo_id=HF_DATASET_ID, repo_type=\"dataset\", filename=manifest_path))\n",
        "\n",
        "    # Load metadata and embeddings\n",
        "    ids, metas = read_metadata_jsonl(m_local)\n",
        "    t_vecs = load_npz_vectors(t_local, EMB_DIM)\n",
        "    s_vecs = load_npz_vectors(s_local, EMB_DIM)\n",
        "\n",
        "    if len(ids) != t_vecs.shape[0] or len(ids) != s_vecs.shape[0]:\n",
        "        raise ValueError(f\"Row count mismatch in batch {batch.get('batch_id')}\")\n",
        "\n",
        "    # Upsert to collections\n",
        "    upsert_in_chunks(topic_coll, ids, t_vecs, metas)\n",
        "    upsert_in_chunks(stance_coll, ids, s_vecs, metas)\n",
        "\n",
        "    return {\n",
        "        \"batch_id\": batch.get(\"batch_id\"),\n",
        "        \"docs\": len(ids),\n",
        "        \"topic_count\": topic_coll.count(),\n",
        "        \"stance_count\": stance_coll.count(),\n",
        "    }\n",
        "\n",
        "# Run\n",
        "REGISTRY = load_registry(REGISTRY_PATH)\n",
        "batches = REGISTRY.get(\"batches\", [])\n",
        "\n",
        "client, topic_coll, stance_coll = ensure_chroma()\n",
        "\n",
        "if not batches:\n",
        "    print(\"No batches in registry. Initialized empty Chroma collections.\")\n",
        "    print({\n",
        "        \"topic_collection\": COLL_TOPIC,\n",
        "        \"stance_collection\": COLL_STANCE,\n",
        "        \"topic_count\": topic_coll.count(),\n",
        "        \"stance_count\": stance_coll.count(),\n",
        "        \"store\": str(CHROMA_DIR),\n",
        "    })\n",
        "else:\n",
        "    print(f\"Ingesting {len(batches)} batch(es) from HF dataset {HF_DATASET_ID}\")\n",
        "    totals = []\n",
        "    for b in batches:\n",
        "        try:\n",
        "            res = ingest_batch_record(b, topic_coll, stance_coll)\n",
        "            print(f\"Ingested batch {res['batch_id']}: +{res['docs']} docs\")\n",
        "            totals.append(res)\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: failed to ingest batch {b.get('batch_id')}: {type(e).__name__}: {e}\")\n",
        "\n",
        "    print(\"Chroma rebuild summary:\")\n",
        "    print({\n",
        "        \"topic_count\": topic_coll.count(),\n",
        "        \"stance_count\": stance_coll.count(),\n",
        "        \"batches_ingested\": len(totals),\n",
        "        \"store\": str(CHROMA_DIR),\n",
        "    })\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFlG77sFNAzu",
        "outputId": "865a2183-bba3-4e07-d8e3-3995dae721e6"
      },
      "id": "cFlG77sFNAzu",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No batches in registry. Initialized empty Chroma collections.\n",
            "{'topic_collection': 'news_topic', 'stance_collection': 'news_stance', 'topic_count': 0, 'stance_count': 0, 'store': '/content/anti_echo/chroma_db'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup 5A: tunables and Guardian feeds\n",
        "\n",
        "Use this cell to:\n",
        "- Set how many total articles to scrape per run\n",
        "- Set optional per feed caps\n",
        "- Pick the date floor\n",
        "- Control even distribution across feeds (with remainder to a preferred feed)\n",
        "- Define the full Guardian feed list in one place\n",
        "\n",
        "Notes\n",
        "- The current default will scrape 30 total articles, evenly split across the feeds below, with any remainder to Comment is Free.\n",
        "- If MAX_ARTICLES is smaller than the number of feeds, many feeds will get 0 for that run. Increase MAX_ARTICLES to cover more feeds per run.\n",
        "- We will wire the scraper to read these values from the environment and JSON so you can change them here only.\n"
      ],
      "metadata": {
        "id": "AR-rVGInQqeZ"
      },
      "id": "AR-rVGInQqeZ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup 5A: tunables and Guardian feeds\n",
        "\n",
        "import os, json\n",
        "\n",
        "# ---- How many articles and distribution policy ----\n",
        "MAX_ARTICLES = 250              # total across all feeds this run\n",
        "MAX_PER_FEED = None            # None for no hard cap, or set an int (e.g., 3)\n",
        "DATE_FROM = \"2025-07-01\"       # ISO-8601 UTC lower bound; set None to ignore\n",
        "FORCE_REFETCH = False          # True to re-download even if cached\n",
        "EVEN_SPLIT = True              # True to evenly split MAX_ARTICLES across feeds\n",
        "QUOTA_REMAINDER_TO = \"commentisfree\"  # where to send the remainder from the even split\n",
        "\n",
        "# ---- Guardian feeds (edit here to add/remove) ----\n",
        "GUARDIAN_FEEDS = [\n",
        "    (\"world\",           \"https://www.theguardian.com/world/rss\"),\n",
        "    (\"uk-news\",         \"https://www.theguardian.com/uk-news/rss\"),\n",
        "    (\"us-news\",         \"https://www.theguardian.com/us-news/rss\"),\n",
        "    (\"politics\",        \"https://www.theguardian.com/politics/rss\"),\n",
        "    (\"europe\",          \"https://www.theguardian.com/world/europe/rss\"),\n",
        "    (\"americas\",        \"https://www.theguardian.com/world/americas/rss\"),\n",
        "    (\"asia\",            \"https://www.theguardian.com/world/asia/rss\"),\n",
        "    (\"australia-news\",  \"https://www.theguardian.com/australia-news/rss\"),\n",
        "    (\"business\",        \"https://www.theguardian.com/uk/business/rss\"),\n",
        "    (\"money\",           \"https://www.theguardian.com/uk/money/rss\"),\n",
        "    (\"technology\",      \"https://www.theguardian.com/uk/technology/rss\"),\n",
        "    (\"science\",         \"https://www.theguardian.com/science/rss\"),\n",
        "    (\"global-development\",\"https://www.theguardian.com/global-development/rss\"),\n",
        "    (\"environment\",     \"https://www.theguardian.com/uk/environment/rss\"),\n",
        "    (\"wildlife\",        \"https://www.theguardian.com/environment/wildlife/rss\"),\n",
        "    (\"pollution\",       \"https://www.theguardian.com/environment/pollution/rss\"),\n",
        "    (\"climate-crisis\",  \"https://www.theguardian.com/environment/climate-crisis/rss\"),\n",
        "    (\"sport\",           \"https://www.theguardian.com/uk/sport/rss\"),\n",
        "    (\"football\",        \"https://www.theguardian.com/football/rss\"),\n",
        "    (\"cricket\",         \"https://www.theguardian.com/sport/cricket/rss\"),\n",
        "    (\"tennis\",          \"https://www.theguardian.com/sport/tennis/rss\"),\n",
        "    (\"golf\",            \"https://www.theguardian.com/sport/golf/rss\"),\n",
        "    (\"formulaone\",      \"https://www.theguardian.com/sport/formulaone/rss\"),\n",
        "    (\"cycling\",         \"https://www.theguardian.com/sport/cycling/rss\"),\n",
        "    (\"rugby-union\",     \"https://www.theguardian.com/sport/rugby-union/rss\"),\n",
        "    (\"culture\",         \"https://www.theguardian.com/uk/culture/rss\"),\n",
        "    (\"film\",            \"https://www.theguardian.com/uk/film/rss\"),\n",
        "    (\"music\",           \"https://www.theguardian.com/music/rss\"),\n",
        "    (\"artanddesign\",    \"https://www.theguardian.com/artanddesign/rss\"),\n",
        "    (\"books\",           \"https://www.theguardian.com/books/rss\"),\n",
        "    (\"tv-and-radio\",    \"https://www.theguardian.com/uk/tv-and-radio/rss\"),\n",
        "    (\"lifestyle\",       \"https://www.theguardian.com/uk/lifeandstyle/rss\"),\n",
        "    (\"family\",          \"https://www.theguardian.com/lifeandstyle/family/rss\"),\n",
        "    (\"health\",          \"https://www.theguardian.com/lifeandstyle/health-and-wellbeing/rss\"),\n",
        "    (\"inequality\",      \"https://www.theguardian.com/inequality/rss\"),\n",
        "    (\"obituaries\",      \"https://www.theguardian.com/tone/obituaries/rss\"),\n",
        "    (\"travel\",          \"https://www.theguardian.com/uk/travel/rss\"),\n",
        "    (\"fashion\",         \"https://www.theguardian.com/fashion/rss\"),\n",
        "    (\"games\",           \"https://www.theguardian.com/games/rss\"),\n",
        "    (\"stage\",           \"https://www.theguardian.com/stage/rss\"),\n",
        "    (\"crosswords\",      \"https://www.theguardian.com/crosswords/rss\"),\n",
        "    (\"commentisfree\",   \"https://www.theguardian.com/commentisfree/rss\")  # opinion\n",
        "]\n",
        "\n",
        "# ---- Export to environment so the scraper can read without edits ----\n",
        "os.environ[\"MAX_ARTICLES\"] = str(MAX_ARTICLES)\n",
        "os.environ[\"MAX_PER_FEED\"] = \"\" if MAX_PER_FEED is None else str(MAX_PER_FEED)\n",
        "os.environ[\"DATE_FROM\"] = \"\" if DATE_FROM in (None, \"\") else DATE_FROM\n",
        "os.environ[\"FORCE_REFETCH\"] = \"true\" if FORCE_REFETCH else \"false\"\n",
        "os.environ[\"EVEN_SPLIT\"] = \"true\" if EVEN_SPLIT else \"false\"\n",
        "os.environ[\"QUOTA_REMAINDER_TO\"] = QUOTA_REMAINDER_TO\n",
        "\n",
        "# Serialize feeds to JSON as a list of [name, url]\n",
        "os.environ[\"GUARDIAN_FEEDS_JSON\"] = json.dumps(GUARDIAN_FEEDS)\n",
        "\n",
        "print(\"Tunables and Guardian feeds set.\")\n",
        "print(f\"Feeds configured: {len(GUARDIAN_FEEDS)}\")\n",
        "print(f\"MAX_ARTICLES={MAX_ARTICLES}, MAX_PER_FEED={MAX_PER_FEED}, DATE_FROM={DATE_FROM}, EVEN_SPLIT={EVEN_SPLIT}, REMAINDER_TO={QUOTA_REMAINDER_TO}\")\n"
      ],
      "metadata": {
        "id": "wAULiUriQr9n",
        "outputId": "b0b3ff8c-a234-45ac-dafc-b876d75b454e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "wAULiUriQr9n",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tunables and Guardian feeds set.\n",
            "Feeds configured: 42\n",
            "MAX_ARTICLES=250, MAX_PER_FEED=None, DATE_FROM=2025-07-01, EVEN_SPLIT=True, REMAINDER_TO=commentisfree\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}