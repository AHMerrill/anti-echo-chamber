{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "eb0d9c13-7874-47ea-8c6e-c2003d5c6762",
      "metadata": {
        "id": "eb0d9c13-7874-47ea-8c6e-c2003d5c6762"
      },
      "source": [
        "# Anti Echo Chamber\n",
        "\n",
        "This notebook does the following things:\n",
        "- Load topic and stance embeddings from Hugging Face\n",
        "- Load transformer models for topic, stance, and summarization\n",
        "- Upload and analyze a news article\n",
        "- Retrieve similar topics with opposing viewpoints\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e8b420c6-8c50-4968-ae9f-9d8052200484",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8b420c6-8c50-4968-ae9f-9d8052200484",
        "outputId": "732b459b-1734-4828-daa7-5f1512456e44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m61.4/67.3 kB\u001b[0m \u001b[31m133.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.9/19.9 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.2/452.2 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# ====================================================\n",
        "# Setup\n",
        "# ====================================================\n",
        "!pip install -q chromadb sentence-transformers transformers huggingface-hub pymupdf beautifulsoup4 scikit-learn\n",
        "\n",
        "import os, json, gc, requests\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from huggingface_hub import hf_hub_download\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from bs4 import BeautifulSoup\n",
        "import fitz\n",
        "import chromadb\n",
        "from google.colab import files\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# --- Disable telemetry noise ---\n",
        "os.environ[\"CHROMA_TELEMETRY_ENABLED\"] = \"false\"\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "os.environ[\"TRANSFORMERS_VERBOSITY\"] = \"error\"\n",
        "\n",
        "# ====================================================\n",
        "# Configuration\n",
        "# ====================================================\n",
        "HF_DATASET_ID = \"zanimal/anti-echo-artifacts\"\n",
        "REPO_OWNER = \"AHMerrill\"\n",
        "REPO_NAME = \"anti-echo-chamber\"\n",
        "BRANCH = \"main\"\n",
        "\n",
        "TOPIC_MODEL_NAME  = \"intfloat/e5-base-v2\"\n",
        "STANCE_MODEL_NAME = \"Snowflake/snowflake-arctic-embed-l\"\n",
        "SUMMARIZER_MODEL_NAME = \"facebook/bart-large-cnn\"\n",
        "\n",
        "CHROMA_DIR = Path(\"chroma_db\")\n",
        "TOPIC_COLL_NAME = \"news_topic\"\n",
        "STANCE_COLL_NAME = \"news_stance\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73f6eb96-5875-4c73-aba7-4d23b225bb56",
      "metadata": {
        "id": "73f6eb96-5875-4c73-aba7-4d23b225bb56"
      },
      "source": [
        "## Load or Rebuild Chroma from Hugging Face Dataset\n",
        "This step fetches topic and stance embeddings from your Hugging Face dataset and constructs local Chroma collections.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e06f6fe1-ca11-49b4-8d35-0f9dd1e7dbe9",
      "metadata": {
        "id": "e06f6fe1-ca11-49b4-8d35-0f9dd1e7dbe9"
      },
      "outputs": [],
      "source": [
        "# ====================================================\n",
        "# Load or rebuild Chroma collections\n",
        "# ====================================================\n",
        "if CHROMA_DIR.exists():\n",
        "    print(\"Using existing local Chroma database.\")\n",
        "    client = chromadb.PersistentClient(path=str(CHROMA_DIR))\n",
        "else:\n",
        "    print(\"Rebuilding Chroma collections from Hugging Face dataset...\")\n",
        "    CHROMA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    client = chromadb.PersistentClient(path=str(CHROMA_DIR))\n",
        "    topic_coll = client.get_or_create_collection(TOPIC_COLL_NAME, metadata={\"hnsw:space\": \"cosine\"})\n",
        "    stance_coll = client.get_or_create_collection(STANCE_COLL_NAME, metadata={\"hnsw:space\": \"cosine\"})\n",
        "\n",
        "    REGISTRY_URL = f\"https://raw.githubusercontent.com/{REPO_OWNER}/{REPO_NAME}/{BRANCH}/artifacts/artifacts_registry.json\"\n",
        "    REGISTRY = requests.get(REGISTRY_URL, timeout=30).json()\n",
        "\n",
        "    for b in REGISTRY.get(\"batches\", []):\n",
        "        paths = b.get(\"paths\") or {}\n",
        "        if not all(k in paths for k in [\"embeddings_topic\", \"embeddings_stance\", \"metadata_topic\", \"metadata_stance\"]):\n",
        "            continue\n",
        "\n",
        "        t_vecs = np.load(hf_hub_download(HF_DATASET_ID, paths[\"embeddings_topic\"], repo_type=\"dataset\"))[\"arr_0\"]\n",
        "        s_vecs = np.load(hf_hub_download(HF_DATASET_ID, paths[\"embeddings_stance\"], repo_type=\"dataset\"))[\"arr_0\"]\n",
        "\n",
        "        t_meta = [json.loads(l) for l in open(hf_hub_download(HF_DATASET_ID, paths[\"metadata_topic\"], repo_type=\"dataset\"), encoding=\"utf-8\")]\n",
        "        s_meta = [json.loads(l) for l in open(hf_hub_download(HF_DATASET_ID, paths[\"metadata_stance\"], repo_type=\"dataset\"), encoding=\"utf-8\")]\n",
        "\n",
        "        topic_coll.upsert(\n",
        "            ids=[m.get(\"id\", f\"topic::{i}\") for i, m in enumerate(t_meta)],\n",
        "            embeddings=t_vecs.tolist(),\n",
        "            metadatas=t_meta\n",
        "        )\n",
        "        stance_coll.upsert(\n",
        "            ids=[m.get(\"id\", f\"stance::{i}\") for i, m in enumerate(s_meta)],\n",
        "            embeddings=s_vecs.tolist(),\n",
        "            metadatas=s_meta\n",
        "        )\n",
        "\n",
        "topic_coll = client.get_collection(TOPIC_COLL_NAME)\n",
        "stance_coll = client.get_collection(STANCE_COLL_NAME)\n",
        "print(f\"Chroma ready with {topic_coll.count()} topic and {stance_coll.count()} stance vectors.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf04491a-972d-4031-b6f5-0b5b8f5b32ea",
      "metadata": {
        "id": "cf04491a-972d-4031-b6f5-0b5b8f5b32ea"
      },
      "source": [
        "## Load Embedding and Summarization Models\n",
        "We will use the following:\n",
        "- intfloat/e5-base-v2 for topic and stance embeddings\n",
        "- facebook/bart-large-cnn for summarization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8de0dd9-3903-414a-9b62-fef076cdc7a0",
      "metadata": {
        "id": "b8de0dd9-3903-414a-9b62-fef076cdc7a0"
      },
      "outputs": [],
      "source": [
        "# ====================================================\n",
        "# Load embedding + summarization models\n",
        "# ====================================================\n",
        "print(\"Loading models...\")\n",
        "topic_model  = SentenceTransformer(TOPIC_MODEL_NAME)\n",
        "stance_model = SentenceTransformer(STANCE_MODEL_NAME)\n",
        "tok_sum  = AutoTokenizer.from_pretrained(SUMMARIZER_MODEL_NAME)\n",
        "model_sum = AutoModelForSeq2SeqLM.from_pretrained(SUMMARIZER_MODEL_NAME)\n",
        "print(\"Models loaded successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d35a3a82-e939-4acd-aa79-72b9d2f8d128",
      "metadata": {
        "id": "d35a3a82-e939-4acd-aa79-72b9d2f8d128"
      },
      "source": [
        "## Upload an Article\n",
        "Upload a .txt, .pdf, or .html file for analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8cd0f63-868b-494b-a655-177813c2829f",
      "metadata": {
        "id": "d8cd0f63-868b-494b-a655-177813c2829f"
      },
      "outputs": [],
      "source": [
        "# ====================================================\n",
        "# Upload and extract article\n",
        "# ====================================================\n",
        "uploaded = files.upload()\n",
        "filename = list(uploaded.keys())[0]\n",
        "ext = Path(filename).suffix.lower()\n",
        "\n",
        "def extract_text(file_path):\n",
        "    if ext == \".txt\":\n",
        "        return open(file_path, encoding=\"utf-8\", errors=\"ignore\").read()\n",
        "    elif ext == \".pdf\":\n",
        "        text = \"\"\n",
        "        with fitz.open(file_path) as doc:\n",
        "            for page in doc:\n",
        "                text += page.get_text()\n",
        "        return text\n",
        "    elif ext == \".html\":\n",
        "        html = open(file_path, encoding=\"utf-8\", errors=\"ignore\").read()\n",
        "        soup = BeautifulSoup(html, \"html.parser\")\n",
        "        return soup.get_text(separator=\"\\n\")\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file type\")\n",
        "\n",
        "text = extract_text(filename)\n",
        "display(Markdown(f\"**Extracted first 2,000 characters:**\\n\\n{text[:2000]}...\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afdbe1cb-63fb-4f08-a8ea-f2324703c18b",
      "metadata": {
        "id": "afdbe1cb-63fb-4f08-a8ea-f2324703c18b"
      },
      "source": [
        "## Summarize and Compute Embeddings\n",
        "This step summarizes the article for stance analysis, then embeds both the summary and full text for topic analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e965da0-87f5-465e-95c2-036e7ee34155",
      "metadata": {
        "id": "5e965da0-87f5-465e-95c2-036e7ee34155"
      },
      "outputs": [],
      "source": [
        "# ====================================================\n",
        "# Summarize and compute embeddings\n",
        "# ====================================================\n",
        "inputs = tok_sum([text], return_tensors=\"pt\", truncation=True, max_length=1024)\n",
        "summary_ids = model_sum.generate(**inputs, max_length=150, num_beams=4, early_stopping=True)\n",
        "summary = tok_sum.batch_decode(summary_ids, skip_special_tokens=True)[0].strip()\n",
        "\n",
        "# Stance vector from summary (same encoder used for stance collection)\n",
        "stance_vec = stance_model.encode([summary], normalize_embeddings=True)[0]\n",
        "\n",
        "# Topic embedding uses both summary + main text for robustness\n",
        "topic_vecs = topic_model.encode([summary, text[:3000]], normalize_embeddings=True)\n",
        "topic_vec_mean = topic_vecs.mean(axis=0)\n",
        "\n",
        "display(Markdown(f\"### One-sentence Summary\\n> {summary}\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdb94bce-0c44-452a-bef2-56feed9c8924",
      "metadata": {
        "id": "cdb94bce-0c44-452a-bef2-56feed9c8924"
      },
      "source": [
        "## Query for Similar Topics\n",
        "Retrieve the 100 most similar articles by topic embedding.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59b4bddb-a764-4152-9980-bc44840c3a5f",
      "metadata": {
        "id": "59b4bddb-a764-4152-9980-bc44840c3a5f"
      },
      "outputs": [],
      "source": [
        "# ====================================================\n",
        "# Retrieve similar topics\n",
        "# ====================================================\n",
        "results = topic_coll.query(\n",
        "    query_embeddings=[topic_vec_mean.tolist()],\n",
        "    n_results=100,\n",
        "    include=[\"metadatas\"]\n",
        ")\n",
        "flat_results = [m for batch in results[\"metadatas\"] for m in batch]\n",
        "print(f\"Found {len(flat_results)} potential topic matches.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2a04d60-f69d-4e52-9b8c-1d466ded896e",
      "metadata": {
        "id": "f2a04d60-f69d-4e52-9b8c-1d466ded896e"
      },
      "source": [
        "## Rank by Opposing Stance\n",
        "We compute cosine similarity between stance embeddings and display opposing viewpoints first.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "024a09cb-a683-491f-9078-53e01977e4db",
      "metadata": {
        "id": "024a09cb-a683-491f-9078-53e01977e4db"
      },
      "outputs": [],
      "source": [
        "# ====================================================\n",
        "# Rank by opposing stance\n",
        "# ====================================================\n",
        "if not flat_results:\n",
        "    display(Markdown(\"No topic matches found.\"))\n",
        "else:\n",
        "    # Use stance summary text for stance embeddings\n",
        "    stance_texts = [\n",
        "        f\"{m.get('political_leaning','')}\\n{m.get('implied_stance','')}\\n{m.get('stance_summary_text','')}\"\n",
        "        for m in flat_results\n",
        "    ]\n",
        "    stance_embeddings = stance_model.encode(stance_texts, normalize_embeddings=True)\n",
        "    stance_sims = cosine_similarity([stance_vec], stance_embeddings)[0]\n",
        "\n",
        "    # Lower similarity = more opposing\n",
        "    ranked = sorted(zip(flat_results, stance_sims), key=lambda x: x[1])\n",
        "\n",
        "    def sim_label(s):\n",
        "        if s < 0.2: return \"Very Dissimilar\"\n",
        "        elif s < 0.4: return \"Dissimilar\"\n",
        "        elif s < 0.6: return \"Somewhat Similar\"\n",
        "        elif s < 0.8: return \"Similar\"\n",
        "        else: return \"Very Similar\"\n",
        "\n",
        "    display(Markdown(\"### Results: Similar Topics, Contrasting Perspectives\"))\n",
        "    for meta, sim in ranked[:10]:\n",
        "        topic_display = meta.get(\"topic_label\") or meta.get(\"inferred_topic\") or \"(topic unknown)\"\n",
        "        leaning = meta.get(\"political_leaning\", \"\")\n",
        "        stance  = meta.get(\"implied_stance\", \"\")\n",
        "        summary = meta.get(\"stance_summary_text\", \"\")\n",
        "        md = f\"\"\"\n",
        "**{meta.get('title','(untitled)')}**\n",
        "Source: {meta.get('domain','unknown')}\n",
        "Topic: *{topic_display}*\n",
        "Political Leaning: `{leaning}`\n",
        "Implied Stance: `{stance}`\n",
        "Stance Similarity: {sim:.2f} ({sim_label(sim)})\n",
        "\n",
        "{summary}\n",
        "\n",
        "[Read original article]({meta.get('url','#')})\n",
        "\"\"\"\n",
        "        display(Markdown(md))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f9af150-b65e-433e-ac61-42a5fcca2acf",
      "metadata": {
        "id": "4f9af150-b65e-433e-ac61-42a5fcca2acf"
      },
      "source": [
        "## Cleanup\n",
        "Free GPU and CPU memory after analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06bb1c51-29fb-44e6-a312-7857644d8a84",
      "metadata": {
        "id": "06bb1c51-29fb-44e6-a312-7857644d8a84"
      },
      "outputs": [],
      "source": [
        "# ====================================================\n",
        "# Cleanup\n",
        "# ====================================================\n",
        "del text, summary, stance_vec, topic_vec_mean, topic_vecs\n",
        "gc.collect()\n",
        "print(\"Memory cleared.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}